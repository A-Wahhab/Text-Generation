{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "saving.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSqILVCImNlp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from random import randint\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import RNN\n",
        "from keras.utils import np_utils\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "text = (open(\"fFinal.txt\", encoding = \"ISO-8859-1\").read())\n",
        "text = text.lower()\n",
        "\n",
        "characters = sorted(list(set(text)))\n",
        "\n",
        "n_to_char = {n:char for n, char in enumerate(characters)}\n",
        "char_to_n = {char:n for n, char in enumerate(characters)}\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "length = len(text)\n",
        "seq_length = 100\n",
        "\n",
        "for i in range(0, length-seq_length, 1):\n",
        "    sequence = text[i:i + seq_length]\n",
        "    label =text[i + seq_length]\n",
        "    X.append([char_to_n[char] for char in sequence])\n",
        "    Y.append(char_to_n[label])\n",
        "X_modified = np.reshape(X, (len(X), seq_length, 1))\n",
        "X_modified = X_modified / float(len(characters))\n",
        "Y_modified = np_utils.to_categorical(Y)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM (700, input_shape=(X_modified.shape[1], X_modified.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(700))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(Y_modified.shape[1], activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "history = model.fit(X_modified, Y_modified, epochs=50, batch_size=50, verbose=1)\n",
        "\n",
        "model.evaluate(X_modified, Y_modified, batch_size=50, verbose=2)\n",
        "\n",
        "\n",
        "model.save('Train1.h5')\n",
        "\n",
        "history = model\n",
        "index = randint(0, 400)\n",
        "\n",
        "string_mapped = X[index]\n",
        "full_string = [n_to_char[value] for value in string_mapped]\n",
        "# generating characters\n",
        "for i in range(400):\n",
        "    x = np.reshape(string_mapped,(1,len(string_mapped), 1))\n",
        "    x = x / float(len(characters))\n",
        "\n",
        "    pred_index = np.argmax(model.predict(x, verbose=0))\n",
        "    seq = [n_to_char[value] for value in string_mapped]\n",
        "    full_string.append(n_to_char[pred_index])\n",
        "\n",
        "    string_mapped.append(pred_index)\n",
        "    string_mapped = string_mapped[1:len(string_mapped)]\n",
        "#combining text\n",
        "txt=\"\"\n",
        "for char in full_string:\n",
        "    txt = txt+char\n",
        "print(txt)\n",
        "\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "print(\"------------------------------------accuracy-------------------------------\")\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "print(\"------------------------------------loss-------------------------------\")\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    }
  ]
}